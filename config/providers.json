{
  "providers": [
    {
      "id": "kimi",
      "name": "Kimi/Moonshot AI",
      "api_url": "https://api.moonshot.cn/v1",
      "type": "primary",
      "api_key_env": "MOONSHOT_API_KEY",
      "models": {
        "default": "moonshot-v1-8k",
        "available": ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"]
      },
      "rate_limits": {
        "rpm": 3,
        "requests_per_minute": 3
      },
      "priority": 1,
      "enabled": true,
      "notes": "Primary provider - highest quality"
    },
    {
      "id": "openrouter",
      "name": "OpenRouter",
      "api_url": "https://openrouter.ai/api/v1",
      "type": "fallback",
      "api_key_env": "OPENROUTER_API_KEY",
      "rate_limits": {
        "rpm": 200,
        "requests_per_minute": 200
      },
      "priority": 2,
      "enabled": true,
      "notes": "Fallback provider - 50+ free models available",
      "tiers": {
        "tier1_quality": {
          "description": "Best quality - use for critical tasks (reasoning & large models)",
          "models": [
            "deepseek/deepseek-r1:free",
            "deepseek/deepseek-r1-0528:free",
            "deepseek/deepseek-r1-0528-qwen3-8b:free",
            "deepseek/deepseek-chat-v3-0324:free",
            "deepseek/deepseek-chat-v3.1:free",
            "deepseek/deepseek-r1-distill-llama-70b:free",
            "deepseek/deepseek-r1t-chimera:free",
            "tngtech/deepseek-r1t2-chimera:free",
            "qwen/qwen3-235b-a22b:free",
            "qwen/qwen3-30b-a3b:free",
            "qwen/qwen3-14b:free",
            "google/gemini-2.0-flash-exp:free",
            "meta-llama/llama-4-maverick:free",
            "meta-llama/llama-4-scout:free",
            "meta-llama/llama-3.3-70b-instruct:free",
            "mistralai/mistral-small-3.2-24b-instruct:free",
            "google/gemma-3-27b-it:free",
            "google/gemma-3-12b-it:free",
            "moonshotai/kimi-k2:free",
            "z-ai/glm-4.5-air:free"
          ]
        },
        "tier2_balanced": {
          "description": "Good quality and reasonable speed (balanced models)",
          "models": [
            "qwen/qwen3-8b:free",
            "google/gemma-3-4b-it:free",
            "google/gemma-3n-e4b-it:free",
            "google/gemma-3n-e2b-it:free",
            "mistralai/mistral-small-3.1-24b-instruct:free",
            "mistralai/mistral-small-24b-instruct-2501:free",
            "mistralai/devstral-small-2505:free",
            "google/gemma-2-9b-it:free",
            "meta-llama/llama-3.2-3b-instruct:free",
            "meta-llama/llama-3.1-8b-instruct:free",
            "meta-llama/llama-3.3-8b-instruct:free",
            "qwen/qwen-2.5-72b-instruct:free",
            "qwen/qwen-2.5-coder-32b-instruct:free",
            "qwen/qwen2.5-vl-32b-instruct:free",
            "qwen/qwen2.5-vl-72b-instruct:free",
            "qwen/qwen3-coder:free",
            "mistralai/mistral-nemo:free",
            "mistralai/mistral-7b-instruct:free",
            "tencent/hunyuan-a13b-instruct:free",
            "nousresearch/deephermes-3-llama-3-8b-preview:free",
            "cognitivecomputations/dolphin3.0-mistral-24b:free"
          ]
        },
        "tier3_fast": {
          "description": "Fast response - for collection and non-critical tasks",
          "models": [
            "qwen/qwen3-4b:free",
            "nvidia/nemotron-nano-9b-v2:free",
            "alibaba/tongyi-deepresearch-30b-a3b:free",
            "meituan/longcat-flash-chat:free",
            "openai/gpt-oss-20b:free",
            "moonshotai/kimi-dev-72b:free",
            "microsoft/mai-ds-r1:free",
            "shisa-ai/shisa-v2-llama3.3-70b:free",
            "arliai/qwq-32b-arliai-rpr-v1:free",
            "agentica-org/deepcoder-14b-preview:free",
            "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
            "nousresearch/deephermes-3-llama-3-8b-preview:free",
            "google/gemma-3n-e4b-it:free"
          ]
        }
      }
    }
  ],
  "task_model_mapping": {
    "entity_extraction": {
      "preferred_tier": "tier1_quality",
      "reason": "Requires accurate entity recognition from text"
    },
    "article_evaluation": {
      "preferred_tier": "tier1_quality",
      "reason": "Critical for ranking articles"
    },
    "article_paraphrasing": {
      "preferred_tier": "tier1_quality",
      "reason": "Highest quality summaries required"
    },
    "category_selection": {
      "preferred_tier": "tier2_balanced",
      "reason": "Simple classification task"
    },
    "general_chat": {
      "preferred_tier": "tier2_balanced",
      "reason": "Balanced approach"
    },
    "fallback_emergency": {
      "preferred_tier": "tier3_fast",
      "reason": "Last resort when all quality providers rate-limited"
    }
  },
  "fallback_strategy": {
    "description": "Provider switching strategy when rate limits are hit",
    "order": [
      "openrouter.tier1_quality",
      "openrouter.tier2_balanced",
      "openrouter.tier3_fast",
      "kimi"
    ],
    "on_rate_limit": "switch_to_next_provider",
    "max_retries_per_provider": 3,
    "retry_backoff": "exponential",
    "notes": "OpenRouter primary for pipeline (high volume), Kimi fallback. Ask function uses Kimi primary (set in app.py)."
  },
  "caching": {
    "cache_responses": true,
    "cache_by_content": true,
    "provider_agnostic": true,
    "description": "Cache key based on prompt content, not provider"
  }
}
