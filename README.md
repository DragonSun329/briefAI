# BriefAI - Multi-Pipeline AI Intelligence Platform

An intelligent multi-pipeline system for AI industry intelligence, featuring automated news briefings, trend radar, investment tracking, and Chinese AI ecosystem monitoring.

## Overview

**The Problem:** Executives and investors are drowning in AI news. Hundreds of articles daily, most noise.

**BriefAI's Solution:** A signal-to-noise engine that fuses multiple data layers to surface what actually matters:

| Layer | What It Does | Output |
|-------|--------------|--------|
| **News Intelligence** | Scrapes 40+ sources, deduplicates, scores relevance | Daily briefings |
| **Financial Signals** | Tracks stock momentum, funding rounds, CB Rank trends | PMS/MRS scores |
| **Market Sentiment** | Aggregates G2, Capterra, Product Hunt reviews | Consensus NPS |
| **Entity Tracking** | Cross-pipeline company/model mentions | Trend Radar heatmaps |

The result: A single dashboard that answers "What moved in AI today?" in under 60 seconds.

## Architecture

```mermaid
graph TD
    subgraph Input["ğŸ“¥ Data Ingestion"]
        RSS[RSS Feeds]
        API[APIs]
        Scrape[Web Scrapers]
    end

    subgraph Core["ğŸ§  Processing Engine"]
        Dedup[Semantic Deduplication]
        Score[Multi-Dimensional Scoring]
        NER[Entity Extraction]
        Cluster[Topic Clustering]
    end

    subgraph Output["ğŸ“Š Intelligence Layer"]
        Brief[Executive Briefings]
        Radar[Trend Radar]
        Alerts[Smart Alerts]
        Dashboard[React Dashboard]
    end

    RSS --> Dedup
    API --> Dedup
    Scrape --> Dedup
    Dedup --> Score
    Score --> NER
    NER --> Cluster
    Cluster --> Brief
    Cluster --> Radar
    Cluster --> Alerts
    Radar --> Dashboard
    Brief --> Dashboard
    Alerts --> Dashboard
```

## Key Features

### Multi-Pipeline Architecture
| Pipeline | Focus | Sources | Output |
|----------|-------|---------|--------|
| **news** | General AI industry news | TechCrunch, VentureBeat, The Verge, etc. | `ai_briefing_*.md` |
| **product** | AI product launches | Product Hunt, Hacker News, etc. | `product_briefing_*.md` |
| **investing** | VC/funding intelligence | Crunchbase, SEC filings, etc. | `investing_briefing_*.md` |
| **china_ai** | Chinese AI ecosystem | æœºå™¨ä¹‹å¿ƒ, é‡å­ä½, 36æ°ª, etc. | `china_ai_briefing_*.md` |

### Trend Radar
- Cross-pipeline entity tracking
- Historical baseline comparison (4-week rolling)
- Rising/falling signal detection
- Company mention heatmaps

### Data Enrichment
- **Funding data**: Kaggle Crunchbase + ITJuzi + Wikidata SPARQL
- **Product reviews**: G2, Capterra, Product Hunt, App Store ratings
- **Financial signals**: Stock data via yfinance (US) and AKShare (China A-shares)
- **VC portfolios**: OpenBook DoltHub database

### Chinese AI Coverage
- 8 Chinese news sources (RSS + web scraping)
- 6 categories: å›½äº§å¤§æ¨¡å‹, AIç›‘ç®¡æ”¿ç­–, å›½äº§èŠ¯ç‰‡, AIç ”ç©¶, è¡Œä¸šåŠ¨æ€, AIæŠ•èèµ„
- 25+ Chinese AI companies tracked with funding data
- Original Chinese text (åŸæ–‡) output

## Scoring Methodology

BriefAI uses a multi-signal approach inspired by quantitative finance:

| Signal | Description | Data Sources |
|--------|-------------|--------------|
| **Technical Velocity** | GitHub stars growth, HuggingFace downloads, arXiv citations | GitHub API, HF Hub, Semantic Scholar |
| **Capital Conviction** | Funding rounds, CB Rank trajectory, investor quality | Crunchbase, SEC filings, OpenBook VC |
| **Market Sentiment** | Product reviews weighted by platform authority | G2 (1.0x), Capterra (0.9x), Product Hunt (0.7x) |
| **News Momentum** | Article frequency Ã— source credibility Ã— relevance score | 40+ curated sources |

Each company receives a composite score enabling apples-to-apples comparison across the AI landscape.

## Quick Start

### Option A: Docker (Recommended)
```bash
git clone https://github.com/yourusername/briefAI.git
cd briefAI
cp .env.example .env  # Add your API keys
docker-compose up -d --build
# API: http://localhost:8000 | Dashboard: http://localhost:5173
```

### Option B: Manual Installation

#### 1. Install Dependencies
```bash
git clone https://github.com/yourusername/briefAI.git
cd briefAI
pip install -r requirements.txt
cd frontend && npm install && cd ..
```

#### 2. Configuration
Create `.env` file:
```bash
# LLM Providers
MOONSHOT_API_KEY=your_key_here
OPENROUTER_API_KEY=your_key_here
ANTHROPIC_API_KEY=your_key_here

# Optional
DEFAULT_CATEGORIES=fintech_ai,data_analytics,marketing_ai
REPORT_LANGUAGE=zh-CN
```

#### 3. Run the Application

**Start API + Dashboard:**
```bash
# Terminal 1: API server
python -m api.main
# API available at http://localhost:8000

# Terminal 2: React dashboard
cd frontend && npm run dev
# Dashboard at http://localhost:5173
```

**Run pipelines:**
```bash
# Run all pipelines
python pipeline/orchestrator.py --all

# Run specific pipeline
python pipeline/orchestrator.py --pipeline china_ai --date 2026-01-22

# Run with custom date range
python pipeline/orchestrator.py --pipeline news --start-date 2026-01-15 --end-date 2026-01-22
```

## Project Structure

```
briefAI/
â”œâ”€â”€ api/                            # FastAPI backend
â”‚   â”œâ”€â”€ main.py                     # API entry point
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ briefings.py            # Briefing report endpoints
â”‚       â”œâ”€â”€ companies.py            # Company data + stock prices
â”‚       â”œâ”€â”€ trends.py               # Trend radar endpoints
â”‚       â””â”€â”€ alerts.py               # Alert management
â”œâ”€â”€ pipeline/                       # Pipeline orchestration
â”‚   â””â”€â”€ orchestrator.py             # Multi-pipeline runner
â”œâ”€â”€ modules/                        # Core pipeline modules
â”‚   â”œâ”€â”€ web_scraper.py              # RSS/HTML scraping
â”‚   â”œâ”€â”€ news_evaluator.py           # Article scoring
â”‚   â”œâ”€â”€ article_paraphraser.py      # Content summarization
â”‚   â”œâ”€â”€ report_formatter.py         # Report generation
â”‚   â”œâ”€â”€ signals_extractor.py        # Risk signal extraction
â”‚   â””â”€â”€ cluster_engine.py           # DBSCAN clustering
â”œâ”€â”€ scrapers/                       # Data scrapers
â”‚   â”œâ”€â”€ cn_ai_funding_lookup.py     # Chinese AI funding scraper
â”‚   â”œâ”€â”€ cn_funding_importer.py      # Import funding to DB
â”‚   â”œâ”€â”€ product_review_scraper.py   # G2/Capterra/PH reviews
â”‚   â”œâ”€â”€ funding_enricher.py         # Kaggle + Wikidata enrichment
â”‚   â””â”€â”€ openbook_vc_scraper.py      # VC firm database
â”œâ”€â”€ utils/                          # Shared utilities
â”‚   â”œâ”€â”€ llm_client.py               # LLM wrapper
â”‚   â”œâ”€â”€ entity_extractor.py         # spaCy + Claude NER
â”‚   â”œâ”€â”€ scoring_engine.py           # Weighted scoring
â”‚   â”œâ”€â”€ signal_store.py             # SQLite signal storage
â”‚   â””â”€â”€ alert_store.py              # Alert persistence
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ pipelines.json              # Pipeline definitions
â”‚   â”œâ”€â”€ sources.json                # News sources (general)
â”‚   â”œâ”€â”€ sources_china_ai.json       # Chinese AI sources
â”‚   â”œâ”€â”€ categories.json             # Category taxonomy
â”‚   â”œâ”€â”€ categories_china_ai.json    # Chinese categories
â”‚   â””â”€â”€ report_template*.md         # Report templates
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ reports/                    # Generated briefings
â”‚   â”œâ”€â”€ trend_radar.db              # Company/entity tracking
â”‚   â”œâ”€â”€ alerts.db                   # Alert storage
â”‚   â”œâ”€â”€ kaggle/                     # Crunchbase CSV data
â”‚   â””â”€â”€ alternative_signals/        # Scraped signals (JSON)
â””â”€â”€ docs/
    â””â”€â”€ plans/                      # Implementation plans
```

## API Endpoints

| Endpoint | Description |
|----------|-------------|
| `GET /api/briefings/available` | List all available briefings |
| `GET /api/briefings/{pipeline}/{date}` | Get specific briefing |
| `GET /api/companies?market=cn` | List companies (filter by market) |
| `GET /api/companies/{id}/stock` | Get stock price data |
| `GET /api/trends/rising` | Get rising entities |
| `GET /api/alerts` | Get active alerts |

## Data Sources

### News Sources (40+)
- **English**: TechCrunch, VentureBeat, The Verge, Wired, MIT Tech Review, etc.
- **Chinese**: æœºå™¨ä¹‹å¿ƒ, é‡å­ä½, 36æ°ª, æ–°æ™ºå…ƒ, é›·é”‹ç½‘, PaperWeekly, æ™ºæºç¤¾åŒº

### Funding Data
- **Kaggle Crunchbase**: 13,800+ companies with funding rounds
- **ITJuzi**: Chinese startup funding via web search
- **Wikidata SPARQL**: Fallback for public company data

### Alternative Signals
- Product reviews (G2, Capterra, Product Hunt)
- Stock data (yfinance, AKShare for China)
- VC firm databases (OpenBook DoltHub)
- SEC filings

## Chinese AI Companies Tracked

| Category | Companies |
|----------|-----------|
| **LLM** | DeepSeek, Moonshot (Kimi), Zhipu (ChatGLM), Baichuan, MiniMax, 01.AI, Stepfun |
| **Big Tech** | Baidu (æ–‡å¿ƒ), Alibaba (é€šä¹‰), Tencent (æ··å…ƒ), ByteDance (è±†åŒ…), Huawei (ç›˜å¤) |
| **Chips** | Cambricon (å¯’æ­¦çºª), Horizon (åœ°å¹³çº¿), Biren (å£ä»), Moore Threads, Enflame |
| **Vision** | SenseTime, Megvii (Face++), CloudWalk, Yitu |
| **Enterprise** | iFlytek (è®¯é£), Fourth Paradigm |
| **Robotics** | Unitree (å®‡æ ‘) |

## Configuration

### `config/pipelines.json`
Defines pipeline configurations:
```json
{
  "pipelines": {
    "china_ai": {
      "name": "ä¸­å›½AIç”Ÿæ€",
      "sources_file": "sources_china_ai.json",
      "categories_file": "categories_china_ai.json",
      "output_prefix": "china_ai_briefing",
      "enabled": true
    }
  }
}
```

### `config/sources_china_ai.json`
Chinese AI news sources:
```json
{
  "sources": [
    {
      "id": "jiqizhixin_main",
      "name": "æœºå™¨ä¹‹å¿ƒ",
      "type": "rss",
      "rss_url": "https://www.jiqizhixin.com/rss",
      "language": "zh-CN",
      "credibility_score": 9
    }
  ]
}
```

## Development

### Run Tests
```bash
pytest tests/
```

### Type Checking
```bash
pyright
```

### Add New Pipeline
1. Create `config/sources_<pipeline>.json`
2. Create `config/categories_<pipeline>.json`
3. Add pipeline config to `config/pipelines.json`
4. Create report template `config/report_template_<pipeline>.md`
5. Run: `python pipeline/orchestrator.py --pipeline <pipeline>`

## Roadmap

### Completed
- [x] Multi-pipeline architecture (news, product, investing, china_ai)
- [x] Chinese AI ecosystem coverage (25+ companies, 8 sources)
- [x] Funding data enrichment (Kaggle + ITJuzi + Wikidata)
- [x] Product review aggregation (G2, Capterra, Product Hunt, App Store)
- [x] Trend radar with cross-pipeline signals
- [x] React dashboard with company detail views
- [x] CB Rank trend tracking
- [x] China market signals (PMS-CN, MRS-CN) with US/CN market toggle

### In Progress
- [ ] Real-time alert system

### Agentic Architecture (Next Phase)

#### Devil's Advocate Workflow
Multi-agent adversarial analysis to filter hype from substance:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Hype-Man      â”‚     â”‚    Skeptic      â”‚     â”‚    Arbiter      â”‚
â”‚   Agent         â”‚â”€â”€â”€â”€â–¶â”‚    Agent        â”‚â”€â”€â”€â”€â–¶â”‚    (Synthesis)  â”‚
â”‚                 â”‚     â”‚                 â”‚     â”‚                 â”‚
â”‚ â€¢ GitHub stars  â”‚     â”‚ â€¢ SEC filings   â”‚     â”‚ Only surfaces   â”‚
â”‚ â€¢ HF downloads  â”‚     â”‚ â€¢ VC portfolios â”‚     â”‚ trends where    â”‚
â”‚ â€¢ Paper cites   â”‚     â”‚ â€¢ Revenue data  â”‚     â”‚ Skeptic fails   â”‚
â”‚ â€¢ News volume   â”‚     â”‚ â€¢ Deployment    â”‚     â”‚ to refute       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why:** Mimics an investment committee. Filters "noisy" trends with high volume but low substance.

#### JIT Context Loading (MCP Integration)
Dynamic tool invocation to reduce context pollution:

- **Trigger-based**: Only deep-dive when thresholds hit (e.g., >500 GitHub stars in 48h)
- **Model Context Protocol**: Agent "pulls" data on-demand vs. dumping everything
- **Benefit**: 70% token reduction, fewer hallucinations

#### Shadow Mode Backtesting
Prove predictions work before trusting them:

```bash
# Retrospective analysis
python backtest.py --date 2025-07-01 --predict-horizon 90d

# Output: "Predicted rise of Cursor IDE 3 months before mainstream coverage"
# Accuracy: 78% on technical momentum signals
```

- Ingest historical data (e.g., Jan 2025)
- Generate predictions for Q3 2025
- Score against actual outcomes
- Tune signal weights based on accuracy

### Future Vision
- [ ] **Adversarial Analysis**: Hype-Man vs Skeptic agent personas
- [ ] **MCP Integration**: Just-in-time context loading for anomaly deep-dives
- [ ] **Backtesting Engine**: Shadow mode to validate trend predictions
- [ ] **Predictive Alerts**: Early warning system based on signal convergence
- [ ] **IRM Integration**: Connect to Identify-Respond-Monitor lifecycle

## License

This project is provided as-is for demonstration and internal evaluation.

---

**Last Updated**: January 22, 2026 | **Version**: 3.2 (Agentic Roadmap)
